{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil, os, random, gc, time, traceback\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, Callback\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.applications import InceptionV3, VGG16, ResNet50, InceptionResNetV2, DenseNet201\n",
    "\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dense, Conv2D, Flatten, Activation, Dropout, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D, GlobalMaxPooling2D\n",
    "from keras.losses import binary_crossentropy, categorical_crossentropy\n",
    "\n",
    "import cache_magic\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = \"{:,.2f}\".format\n",
    "\n",
    "DATA_PATH = './data/'\n",
    "MODEL_PATH = './model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rutas a directorios de datos\n",
    "ANNO_COARSE_PATH = DATA_PATH + 'anno_coarse'\n",
    "TRAIN_PATH = ANNO_COARSE_PATH + '/train'\n",
    "VALIDATION_PATH = ANNO_COARSE_PATH + '/val'\n",
    "TEST_PATH = ANNO_COARSE_PATH + '/test'\n",
    "AUGMENTED_DATA_PATH = ANNO_COARSE_PATH + '/augmented'\n",
    "IMG = DATA_PATH + 'img'\n",
    "\n",
    "# Rutas a ficheros de datos\n",
    "ATTR_CLOTH_LIST_FILE = ANNO_COARSE_PATH + '/list_attr_cloth.txt'\n",
    "ATTR_IMG_LIST_FILE = ANNO_COARSE_PATH + '/list_attr_img.txt'\n",
    "PARTITION_FILE = ANNO_COARSE_PATH + '/list_eval_partition.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_partition_files():\n",
    "    data = {}\n",
    "    data['train'] = []\n",
    "    data['test'] = []\n",
    "    data['val'] = []\n",
    "    with open(PARTITION_FILE) as fp:\n",
    "        fp.readline() # Ingorar numero de etiquetas\n",
    "        fp.readline() # Ingorar numero de etiquetas\n",
    "        for line in fp:\n",
    "            fields = line.split()\n",
    "            \n",
    "            img_path = fields[0]\n",
    "            img_path = DATA_PATH + img_path\n",
    "            \n",
    "            partition = fields[1]\n",
    "            data[partition].append(img_path)\n",
    "    return data\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_images = read_partition_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lectura de la lista de atributos (fichero list_attr_cloth.txt)\n",
    "def read_attr_cloth_list():\n",
    "    column_to_attr_name = {}\n",
    "    attr_type_to_columns = {}\n",
    "    \n",
    "    with open(ATTR_CLOTH_LIST_FILE) as fp: \n",
    "        fp.readline() # Ingorar numero de etiquetas\n",
    "        fp.readline() # Ignorar cabecera\n",
    "        column = 0\n",
    "        for line in fp: \n",
    "            fields = line.split()\n",
    "            attr = fields[0]\n",
    "            attr_type = fields[1]\n",
    "            column_to_attr_name[column] = attr\n",
    "            if attr_type in attr_type_to_columns:\n",
    "                attr_type_to_columns[attr_type].append(column)\n",
    "            else:\n",
    "                attr_type_to_columns[attr_type] = [column]\n",
    "            column += 1\n",
    "    return column_to_attr_name, attr_type_to_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column_to_attr_name: Mapping número columna -> Nombre de atributo\n",
    "# attr_type_to_columns: Mapping tipo de atributo - Lista de columnas de atributos de dicho tipo\n",
    "column_to_attr_name, attr_type_to_columns = read_attr_cloth_list()           \n",
    "# Listado con los nombre de los atributos\n",
    "attributes = list(column_to_attr_name.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Devuelve el listado de imágnes del fichero recibido como parámetro\n",
    "def read_image_list(file_name):\n",
    "    file_path = ANNO_COARSE_PATH + '/' + file_name + '.txt'\n",
    "    with open(file_path) as fp:\n",
    "        return [DATA_PATH + img.rstrip('\\n') for img in fp]\n",
    "    \n",
    "# Devuelve el path de la partición a partir del nombre de la partición\n",
    "def build_partition_data_path(partition):\n",
    "    return ANNO_COARSE_PATH + '/' + partition\n",
    "\n",
    "# Creación de la estructura de datos necesaria para los generadores de aumentación de datos\n",
    "def create_data_structure(partition_images, force=False):\n",
    "    for partition in ['test', 'train', 'val']:\n",
    "        partition_data_path = build_partition_data_path(partition)\n",
    "        \n",
    "        # Forzar recarga\n",
    "        if os.path.exists(partition_data_path) and force:\n",
    "            shutil.rmtree(partition_data_path)\n",
    "        \n",
    "        if not os.path.exists(partition_data_path):\n",
    "            os.mkdir(partition_data_path)\n",
    "            # Carga del listado de imágenes\n",
    "            image_list = partition_images[partition]\n",
    "            # Copia\n",
    "            for i, src in enumerate(image_list):\n",
    "                dst = partition_data_path + '/' + str(i) + '.jpg' \n",
    "                shutil.copyfile(src, dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_data_structure(partition_images, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
